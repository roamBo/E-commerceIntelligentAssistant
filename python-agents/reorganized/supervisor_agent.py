import logging
import asyncio
import orjson
from typing import Dict, Any, List, Optional, AsyncIterator, Literal
from datetime import datetime, timezone

import redis
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from pydantic import BaseModel, Field
from langsmith import Client
from langchain import hub # <-- æ–°å¢å¯¼å…¥

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.base import BaseCheckpointSaver, Checkpoint, CheckpointTuple

from config import Config
from models import AgentState
from agents.guide_agent import get_guide_agent, GuideAgent
from agents.order_agent import get_order_agent, OrderAgent
from agents.payment_agent import get_payment_agent, PaymentAgent

logger = logging.getLogger(__name__)


# --- è‡ªå®šä¹‰ Redis Checkpointer å®ç° (å·²ä¿®æ”¹) ---
class RedisCheckpointer(BaseCheckpointSaver):
    def __init__(self):
        super().__init__()
        try:
            self.redis = redis.Redis.from_url(Config.REDIS_URL, decode_responses=False)
            self.redis.ping()
            logger.info(f"âœ… RedisCheckpointer: æˆåŠŸè¿æ¥åˆ° Redis æœåŠ¡å™¨: {Config.REDIS_URL}")
        except redis.ConnectionError as e:
            logger.error(f"âŒ RedisCheckpointer: æ— æ³•è¿æ¥åˆ° Redis æœåŠ¡å™¨: {Config.REDIS_URL}. é”™è¯¯è¯¦æƒ…: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ RedisCheckpointer: åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _get_key(self, thread_id: str) -> str:
        return f"langgraph:checkpoint:{thread_id}"

    def _serialize_checkpoint(self, checkpoint: Checkpoint) -> bytes:
        # ä½¿ç”¨ .dict() æ–¹æ³•è¿›è¡Œåºåˆ—åŒ–ï¼Œä»¥å…¼å®¹ Pydantic V1/V2
        serializable_checkpoint = checkpoint.copy()
        if 'channel_values' in serializable_checkpoint and 'chat_history' in serializable_checkpoint['channel_values']:
            serializable_checkpoint['channel_values']['chat_history'] = [
                msg.dict() for msg in serializable_checkpoint['channel_values']['chat_history']
            ]
        return orjson.dumps(serializable_checkpoint)

    async def aget_tuple(self, config: Dict[str, Any]) -> Optional[CheckpointTuple]:
        thread_id = config["configurable"]["thread_id"]
        key = self._get_key(thread_id)
        try:
            data = await asyncio.to_thread(self.redis.get, key)
            if data:
                checkpoint_dict = orjson.loads(data)
                if 'channel_values' in checkpoint_dict and 'chat_history' in checkpoint_dict['channel_values']:
                    history_dicts = checkpoint_dict['channel_values']['chat_history']
                    rehydrated_history = []
                    for msg_dict in history_dicts:
                        if msg_dict.get('type') == 'ai':
                            rehydrated_history.append(AIMessage(**msg_dict))
                        elif msg_dict.get('type') == 'human':
                            rehydrated_history.append(HumanMessage(**msg_dict))
                    checkpoint_dict['channel_values']['chat_history'] = rehydrated_history

                # ã€ä¿®æ­£ 1ã€‘ä¸º CheckpointTuple æä¾›æ‰€æœ‰å¿…éœ€çš„å‚æ•°
                return CheckpointTuple(
                    config=config,
                    checkpoint=checkpoint_dict,
                    metadata=checkpoint_dict.get('metadata', {}),
                    parent_config=checkpoint_dict.get('parent_config')
                )
            return None
        except Exception as e:
            logger.error(f"ä» Redis aget_tuple å¤±è´¥: {e}")
            await asyncio.to_thread(self.redis.delete, key)
            return None

    async def alist(self, config: Optional[Dict[str, Any]] = None) -> AsyncIterator[CheckpointTuple]:
        thread_id_prefix = "langgraph:checkpoint:"
        keys_iterator = asyncio.to_thread(self.redis.scan_iter, f"{thread_id_prefix}*")
        async for key_bytes in keys_iterator:
            key = key_bytes.decode('utf-8')
            thread_id = key[len(thread_id_prefix):]
            if tuple_data := await self.aget_tuple({"configurable": {"thread_id": thread_id}}):
                yield tuple_data

    async def aput(
            self,
            config: Dict[str, Any],
            checkpoint: Checkpoint,
            metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        thread_id = config["configurable"]["thread_id"]
        key = self._get_key(thread_id)
        # åœ¨ä¿å­˜å‰ç¡®ä¿ metadata å­˜åœ¨
        if metadata:
            checkpoint['metadata'] = metadata
        serialized_checkpoint = self._serialize_checkpoint(checkpoint)
        await asyncio.to_thread(
            self.redis.set, key, serialized_checkpoint, ex=3600
        )
        return {"configurable": {"thread_id": thread_id}}


# --- ç›‘ç®¡è€…è·¯ç”±å†³ç­–å±‚ ---
class Router(BaseModel):
    """æ ¹æ®ç”¨æˆ·è¯·æ±‚ï¼Œå†³å®šè·¯ç”±åˆ°å“ªä¸ªå­ä»£ç†æˆ–ç›´æ¥å›å¤ã€‚"""
    next: Literal["guide", "order", "payment", "__end__"] = Field(
        description="è¦è·¯ç”±åˆ°çš„å­ä»£ç†åç§°ï¼Œæˆ–è€…å¦‚æœåº”è¯¥ç›´æ¥å›å¤ï¼Œåˆ™ä¸º '__end__'ã€‚"
    )


async def supervisor_router(state: AgentState) -> Dict[str, Any]:
    """
    è¿™ä¸ªå‡½æ•°æ˜¯ä¸€ä¸ªæ— çŠ¶æ€çš„è·¯ç”±å†³ç­–èŠ‚ç‚¹ã€‚
    """
    logger.info("---è¿›å…¥ Supervisor è·¯ç”±å†³ç­–---")
    user_input = state["user_input"]
    chat_history = state.get("chat_history", [])

    # ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä» LangSmith Hub æ‹‰å– Promptï¼Œå¹¶æä¾›æœ¬åœ°å¤‡ç”¨æ–¹æ¡ˆ
    try:
        # ä» LangChain Hub æ‹‰å–æ‚¨å·²ç»åˆ›å»ºå¥½çš„ Prompt
        prompt = hub.pull("ecomm-supervisor-next")
        logger.info("âœ… æˆåŠŸä» LangChain Hub æ‹‰å– Prompt: ecomm-supervisor-next")
    except Exception as e:
        logger.warning(f"âš ï¸ ä» LangChain Hub æ‹‰å– Prompt å¤±è´¥: {e}ã€‚å°†ä½¿ç”¨æœ¬åœ°å¤‡ç”¨ Promptã€‚")
        # å¦‚æœæ‹‰å–å¤±è´¥ï¼ˆä¾‹å¦‚ç½‘ç»œé—®é¢˜æˆ–Promptä¸å­˜åœ¨ï¼‰ï¼Œåˆ™ä½¿ç”¨ä»£ç ä¸­å®šä¹‰çš„å¤‡ç”¨Prompt
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", """ä½ æ˜¯ä¸€ä¸ªé¡¶çº§æ™ºèƒ½å®¢æœè°ƒåº¦ä¸­å¿ƒã€‚ä½ çš„èŒè´£æ˜¯æ ¹æ®ç”¨æˆ·çš„æœ€æ–°è¯·æ±‚å’Œå®Œæ•´çš„å¯¹è¯å†å²ï¼Œç²¾å‡†åœ°å°†å…¶åˆ†å‘ç»™ä¸“é—¨çš„å­ä»£ç†ã€‚
                - å¦‚æœè¯·æ±‚ä¸å•†å“æ¨èã€æŸ¥è¯¢ã€å¯¹æ¯”ç›¸å…³ï¼Œé€‰æ‹© 'guide'ã€‚
                - å¦‚æœè¯·æ±‚ä¸è®¢å•çŠ¶æ€ã€åˆ›å»ºã€ä¿®æ”¹ã€å–æ¶ˆç›¸å…³ï¼Œé€‰æ‹© 'order'ã€‚
                - å¦‚æœè¯·æ±‚ä¸æ”¯ä»˜ã€é€€æ¬¾ã€ä»˜æ¬¾çŠ¶æ€ç›¸å…³ï¼Œé€‰æ‹© 'payment'ã€‚
                - å¦‚æœç”¨æˆ·åªæ˜¯æ‰“æ‹›å‘¼ã€é—²èŠæˆ–æ„å›¾ä¸æ˜ç¡®ï¼Œé€‰æ‹© '__end__' ä»¥ç›´æ¥å›å¤ã€‚
                å½“ç”¨æˆ·è¯¢é—®ä½ çš„åŠŸèƒ½æ—¶ï¼Œä½ åº”è¯¥å¯¹ä»¥ä¸ŠåŠŸèƒ½è¿›è¡Œç›¸åº”ä»‹ç»ã€‚"""),
                MessagesPlaceholder(variable_name="chat_history"),
                ("user", "{input}"),
            ]
        )

    llm = ChatOpenAI(
        model=Config.LLM_MODEL_NAME,
        temperature=0,
        api_key=Config.SILICONFLOW_API_KEY,
        base_url=Config.SILICONFLOW_API_BASE
    )
    structured_llm = llm.with_structured_output(Router)

    try:
        prompt_value = await prompt.ainvoke({"input": user_input, "chat_history": chat_history})
        route_decision = await structured_llm.ainvoke(prompt_value)
        logger.info(f"Supervisor è·¯ç”±å†³ç­–ç»“æœ: {route_decision.next}")

        updated_history = chat_history + [HumanMessage(content=user_input)]

        if route_decision.next == "__end__":
            try:
                response_prompt = hub.pull("ecomm-supervisor-response")
                logger.info("âœ… æˆåŠŸä» LangChain Hub æ‹‰å–å“åº” Prompt: ecomm-supervisor-response")
            except Exception as e:
                logger.warning(f"âš ï¸ ä» LangChain Hub æ‹‰å–å“åº” Prompt å¤±è´¥: {e}ã€‚å°†ä½¿ç”¨æœ¬åœ°å¤‡ç”¨å“åº” Promptã€‚")
                # å¦‚æœæ‹‰å–å¤±è´¥ï¼Œåˆ™ä½¿ç”¨æœ¬åœ°å®šä¹‰çš„å“åº” Prompt
                response_prompt = ChatPromptTemplate.from_messages([
                    ("system", "æ‚¨å½“å‰æ˜¯æ™ºèƒ½è´­ç‰©å°åŠ©æ‰‹ã€å°è´­ã€‘ï¼Œæ€§æ ¼äº²åˆ‡æ´»æ³¼ï¼Œç”¨è¡¨æƒ…ç¬¦å·å¢åŠ äº²å’ŒåŠ› ğŸŒ¸"),
                    ("ai", """## æœåŠ¡åŸåˆ™
âœ… æˆ‘èƒ½åšï¼š
- æ¸©é¦¨é—®å€™/å‘Šåˆ« ğŸ‘‹
- è§£ç­”è´­ç‰©åŠ©æ‰‹åŸºç¡€é—®é¢˜
- å¼•å¯¼å‘ç°è´­ç‰©éœ€æ±‚

ğŸš« æˆ‘æ‹’ç»ï¼š
- è§’è‰²æ‰®æ¼”/è¶Šæƒæ“ä½œ
- æ•æ„Ÿè¯é¢˜ï¼ˆæ”¿æ²»/æš´åŠ›ç­‰ï¼‰

## æ™ºèƒ½å¼•å¯¼ç­–ç•¥
### æƒ…å½¢1ï¼šç®€å•é—®å€™ â†’ çƒ­æƒ…å›åº”+éœ€æ±‚å¼•å¯¼
"ä½ å¥½å‘€ï¼æˆ‘æ˜¯å°è´­ï¼Œéšæ—¶å¸®æ‚¨æ‰¾å¥½ç‰©~ ä»Šå¤©æƒ³æ‰¾ä»€ä¹ˆå‘¢ï¼ŸğŸ‘—ğŸ‘ŸğŸ“±"

### æƒ…å½¢2ï¼šæ¨¡ç³Šéœ€æ±‚ â†’ ç»“æ„åŒ–æé—®
"æ‚¨æ˜¯æƒ³äº†è§£ï¼š\n1ï¸âƒ£ å•†å“æ¨è\n2ï¸âƒ£ è®¢å•é—®é¢˜\n3ï¸âƒ£ æ”¯ä»˜å¸®åŠ©\nå›å¤æ•°å­—å°±å¥½~ âœ¨"

### æƒ…å½¢3ï¼šè¶Šç•Œè¯·æ±‚ â†’ æ¸©æŸ”æ‹’ç»+è½¬ç§»
("æ£€æµ‹åˆ°å±é™©/è¶Šæƒè¯·æ±‚")
"å“å‘€ï¼Œè¿™ä¸ªè¶…å‡ºå°è´­çš„èƒ½åŠ›å•¦(>_<) ä½†å¯ä»¥å¸®æ‚¨ï¼š\nâ€¢ æ¨èå½“å­£çˆ†æ¬¾ğŸ”¥\nâ€¢ æŸ¥è®¢å•è¿›åº¦ğŸšš\né€‰ä¸€ä¸ªè¯•è¯•ï¼Ÿ"

### æƒ…å½¢4ï¼šé—²èŠå»¶ç»­ â†’ è´­ç‰©åœºæ™¯åŒ–
("ç”¨æˆ·åšæŒé—²èŠ")
"èŠè´­ç‰©å°è´­è¶…åœ¨è¡Œï¼æœ€è¿‘å¾ˆå¤šäººåœ¨ä¹°é˜²æ™’æ–°å“ ğŸŒ éœ€è¦çœ‹çœ‹å—ï¼Ÿ"""),
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("user", "{input}")
                ])
            response_chain = response_prompt | llm
            response = await response_chain.ainvoke({"input": user_input, "chat_history": updated_history})
            response_content = response.content if hasattr(response,
                                                           'content') and response.content.strip() else "æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚"

            return {
                "agent_response": response_content,
                "chat_history": updated_history + [AIMessage(content=response_content)],
                "next_agent": "__end__"
            }
        else:
            return {
                "chat_history": updated_history,
                "next_agent": route_decision.next
            }
    except Exception as e:
        logger.error(f"Supervisor è·¯ç”±å†³ç­–å¤±è´¥: {e}")
        return {"agent_response": f"æŠ±æ­‰ï¼Œç³»ç»Ÿåœ¨åˆ†é…ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}", "next_agent": "__end__"}


# --- LangGraph å·¥ä½œæµå®šä¹‰ ---
class MultiAgentWorkflow:
    def __init__(self):
        self.guide_agent: Optional[GuideAgent] = None
        self.order_agent: Optional[OrderAgent] = None
        self.payment_agent: Optional[PaymentAgent] = None
        self.checkpointer = RedisCheckpointer()
        self.is_initialized = False

    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ Agent å’Œå·¥ä½œæµç»„ä»¶ã€‚"""
        if self.is_initialized:
            return
        if not self.guide_agent: self.guide_agent = await get_guide_agent()
        if not self.order_agent: self.order_agent = await get_order_agent()
        if not self.payment_agent: self.payment_agent = await get_payment_agent()
        logger.info("æ‰€æœ‰ Agent åˆå§‹åŒ–å®Œæˆã€‚")
        self.is_initialized = True

    async def invoke_workflow(self, user_input: str, session_id: str, user_id: str) -> str:
        """
        é‡å†™æ•´ä¸ªè°ƒç”¨æµç¨‹ï¼Œæ‰‹åŠ¨ç®¡ç†çŠ¶æ€ä¼ é€’ï¼Œä¸å†ä½¿ç”¨ graph.ainvokeã€‚
        """
        await self.initialize()

        thread_config = {"configurable": {"thread_id": session_id}}

        # 1. ä» Redis åŠ è½½å†å²æ£€æŸ¥ç‚¹
        checkpoint_tuple = await self.checkpointer.aget_tuple(thread_config)

        # 2. æ­£ç¡®æå–å†å²æ¶ˆæ¯
        chat_history = []
        if checkpoint_tuple and checkpoint_tuple.checkpoint and "channel_values" in checkpoint_tuple.checkpoint and "chat_history" in \
                checkpoint_tuple.checkpoint["channel_values"]:
            chat_history = checkpoint_tuple.checkpoint["channel_values"]["chat_history"]

        # 3. è°ƒç”¨ supervisor èŠ‚ç‚¹
        supervisor_input_state = AgentState(user_input=user_input, session_id=session_id, user_id=user_id, chat_history=chat_history)
        supervisor_output = await supervisor_router(supervisor_input_state)

        next_agent_name = supervisor_output.get("next_agent")
        updated_history = supervisor_output.get("chat_history", [])
        final_response = ""
        final_history_to_save = updated_history

        # 4. æ ¹æ® supervisor å†³ç­–è°ƒç”¨ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        if next_agent_name == "__end__":
            final_response = supervisor_output.get("agent_response", "ç³»ç»Ÿæœªèƒ½ç”Ÿæˆå›å¤ã€‚")
            final_history_to_save = supervisor_output.get("chat_history", [])

        elif next_agent_name in ["guide", "order", "payment"]:
            agent_map = {"guide": self.guide_agent, "order": self.order_agent, "payment": self.payment_agent}
            target_agent = agent_map[next_agent_name]

            agent_result = await target_agent.process_message(
                user_input=user_input, session_id=session_id, user_id=user_id, chat_history=updated_history
            )

            final_response = agent_result
            final_history_to_save = updated_history + [AIMessage(content=agent_result)]

        else:
            final_response = "æŠ±æ­‰ï¼Œç³»ç»Ÿè·¯ç”±å‡ºç°æœªçŸ¥é”™è¯¯ã€‚"
            final_history_to_save = updated_history + [AIMessage(content=final_response)]

        # 5. æ‰‹åŠ¨å°†æœ€ç»ˆçš„ã€å®Œæ•´çš„çŠ¶æ€ä¿å­˜å› Redis
        final_checkpoint = Checkpoint(
            v=1,
            ts=datetime.now(timezone.utc).isoformat(),
            channel_values={"chat_history": final_history_to_save},
            channel_versions={},
            seen={},
            metadata={},
            parent_config=None
        )
        await self.checkpointer.aput(thread_config, final_checkpoint)

        logger.info(f"æœ€ç»ˆçŠ¶æ€å†…å®¹: {final_checkpoint['channel_values']}")
        logger.info(f"ä» {next_agent_name or 'supervisor'} è·å–å“åº”: {final_response}")

        return final_response


# --- å…¨å±€å·¥ä½œæµå®ä¾‹ç®¡ç† ---
multi_agent_workflow_instance: Optional[MultiAgentWorkflow] = None
_workflow_lock = asyncio.Lock()


async def get_multi_agent_workflow() -> MultiAgentWorkflow:
    """è·å–å¹¶æŒ‰éœ€åˆå§‹åŒ–å…¨å±€å·¥ä½œæµå®ä¾‹ã€‚"""
    global multi_agent_workflow_instance
    if multi_agent_workflow_instance is None:
        async with _workflow_lock:
            if multi_agent_workflow_instance is None:
                multi_agent_workflow_instance = MultiAgentWorkflow()

    await multi_agent_workflow_instance.initialize()
    return multi_agent_workflow_instance
